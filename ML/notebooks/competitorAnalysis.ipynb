{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lang</th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Lang, Text, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/competition.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twitter_scrape(keyword, count, cls):\n",
    "    url = 'http://127.0.0.1:8000/tweets/'\n",
    "    obj = {\n",
    "        \"keyword\": keyword,\n",
    "        \"count\": count\n",
    "        }\n",
    "\n",
    "    r = requests.post(url, json=obj)\n",
    "    data = r.json()\n",
    "    tweets = data['tweets']\n",
    "    for tweet in tweets:\n",
    "        temp = [tweet['lang'], tweet['full_text'], cls]\n",
    "        df.loc[len(df.index)] = temp\n",
    "    \n",
    "    return len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1033"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_scrape(\"icici prudential\", 500, \"icici\")\n",
    "twitter_scrape(\"hdfc insurance\", 500, \"hdfc\")\n",
    "twitter_scrape(\"hdfc life insurance\", 500, \"hdfc\")\n",
    "twitter_scrape(\"icici insurance\", 500, \"icici\")\n",
    "twitter_scrape(\"sbi insurance\", 500, \"sbi\")\n",
    "twitter_scrape(\"sbi life insurance\", 500, \"sbi\")\n",
    "twitter_scrape(\"max life insurance\", 500, \"max\")\n",
    "twitter_scrape(\"max bupa health insurance\", 500, \"max\")\n",
    "twitter_scrape(\"axa xl insurance\", 500, \"xl\")\n",
    "twitter_scrape(\"tata aia\", 500, \"tata\")\n",
    "twitter_scrape(\"tata insurance\", 500, \"tata\")\n",
    "twitter_scrape(\"aia insurance\", 500, \"tata\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True,inplace=True)\n",
    "for i in range(len(df)):\n",
    "    txt = re.sub('[^a-zA-Z]', ' ', df['Text'][i])\n",
    "    txt = txt.lower()\n",
    "    txt = txt.split()\n",
    "    wl = WordNetLemmatizer()\n",
    "    txt = [wl.lemmatize(word) for word in txt if not word in set(stopwords.words('english'))]\n",
    "    txt = ' '.join(txt)\n",
    "    df['Text'][i] = txt\n",
    "\n",
    "new_df = df[df['Lang'] == 'en']\n",
    "new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('../data/competition.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lang</th>\n",
       "      <th>Text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en</td>\n",
       "      <td>rt iciciprulife yorker doosra bouncer surya ku...</td>\n",
       "      <td>icici</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>en</td>\n",
       "      <td>rt cognizantnews cognizant tie max life insura...</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>en</td>\n",
       "      <td>hibah takaful sun life insurance wasiat faraid...</td>\n",
       "      <td>tata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>en</td>\n",
       "      <td>niva bupa niva bupa finally rejected claim sur...</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>en</td>\n",
       "      <td>hdfc life insurance posted net profit r crore ...</td>\n",
       "      <td>hdfc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Lang                                               Text  label\n",
       "0   en  rt iciciprulife yorker doosra bouncer surya ku...  icici\n",
       "1   en  rt cognizantnews cognizant tie max life insura...    max\n",
       "2   en  hibah takaful sun life insurance wasiat faraid...   tata\n",
       "3   en  niva bupa niva bupa finally rejected claim sur...    max\n",
       "4   en  hdfc life insurance posted net profit r crore ...   hdfc"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
